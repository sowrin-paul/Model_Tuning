{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18033e4e",
   "metadata": {},
   "source": [
    "This is a performance testing with the dataset of adolescent on two model. A dual model setup is done here.\n",
    "\n",
    "The first model Electra is going to train on the emotion and the intent of the user and the GPT-2 model is going to generate text based on the questions.\n",
    "\n",
    "The datasets used here -> casual_lm_train.jsonl and masked_lm_train.jsonl\n",
    "\n",
    "casual_lm_train is used for the GPT-2 training and the masked_lm train is for the Electra.\n",
    "\n",
    "gpt-2 performance is going to evaluate by its perplexity that is how certain it's response is or other word what is it's accuracy to predict the next word.\n",
    "\n",
    "electra's performance is evaluated by it's accuracy to the prediction of the emotion and intention of the questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a1c441e8090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    ElectraTokenizerFast, ElectraForSequenceClassification,\n",
    "    GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c0a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 600 samples from masked_lm_train.jsonl\n",
      "Loaded 600 samples from causal_lm_train.jsonl\n",
      "Total samples: 1209\n",
      "Emotion labels (6): ['confused', 'thoughtful', 'curious', 'anxious', 'sad', 'angry']\n",
      "Intent labels (3): ['question', 'seeking support', 'venting']\n",
      "Training samples: 1027\n",
      "Test samples: 182\n",
      "\n",
      "Sample training data:\n",
      "Text: How does your relationship with your mother affect your autonomy?...\n",
      "Emotion: confused, Intent: question\n",
      "Response: That's an important question about family relationships and independence. Let's ...\n",
      "----------------------------------------\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Emotion: thoughtful, Intent: question\n",
      "Response: Having a sense of purpose is crucial for well-being. It gives direction and mean...\n",
      "----------------------------------------\n",
      "Text: What does a high personal growth score mean during adolescence?...\n",
      "Emotion: curious, Intent: question\n",
      "Response: Personal growth is a key part of adolescent development. It shows you're develop...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# data from JSONL files\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line.strip()))\n",
    "        print(f\"Loaded {len(data)} samples from {file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_path} not found!\")\n",
    "        return []\n",
    "    return data\n",
    "\n",
    "masked_lm_data = load_jsonl(\"masked_lm_train.jsonl\")\n",
    "causal_lm_data = load_jsonl(\"causal_lm_train.jsonl\")\n",
    "\n",
    "# convert for classification format for electra\n",
    "extended_data = []\n",
    "\n",
    "# masked LM data for emotion/intent classification\n",
    "for item in masked_lm_data:\n",
    "    sentence1 = item.get('sentence1', '')\n",
    "    sentence2 = item.get('sentence2', '')\n",
    "\n",
    "    if not sentence1:\n",
    "        continue\n",
    "\n",
    "    # extract emotion adn intent\n",
    "    text_lower = sentence1.lower()\n",
    "\n",
    "    # predict intent based on question patterns\n",
    "    if any(word in text_lower for word in ['why', 'how', 'what', 'when', 'where', '?']):\n",
    "        intent = \"question\"\n",
    "    elif any(word in text_lower for word in ['help', 'support', 'advice']):\n",
    "        intent = \"seeking support\"\n",
    "    else:\n",
    "        intent = \"venting\"\n",
    "\n",
    "    # predict emotion based on content patterns - IMPROVED WITH BETTER DETECTION\n",
    "    if any(word in text_lower for word in ['worthless', 'nobody likes', 'hate myself', 'useless', 'sad', 'depressed', 'down', 'upset', 'lonely', 'isolated', 'alone', 'feel like crying', 'feel awful', 'terrible', 'horrible', 'empty', 'hopeless']):\n",
    "        emotion = \"sad\"\n",
    "    elif any(word in text_lower for word in ['anxious', 'anxiety', 'worry', 'worried', 'stress', 'stressed', 'nervous', 'panic', 'overwhelmed', 'can\\'t stop thinking', 'overthinking', 'scared', 'afraid', 'fear']):\n",
    "        emotion = \"anxious\"\n",
    "    elif any(word in text_lower for word in ['angry', 'mad', 'frustrated', 'annoyed', 'furious', 'hate', 'pissed', 'makes me angry', 'irritated', 'rage', 'livid']):\n",
    "        emotion = \"angry\"\n",
    "    elif any(word in text_lower for word in ['mother', 'father', 'parent', 'family', 'relationship', 'independence', 'autonomy', 'confused', 'don\\'t understand', 'mixed up']):\n",
    "        emotion = \"confused\"\n",
    "    elif any(word in text_lower for word in ['growth', 'development', 'maturity', 'change', 'personal', 'curious', 'wonder', 'interested']):\n",
    "        emotion = \"curious\"\n",
    "    else:\n",
    "        emotion = \"thoughtful\"\n",
    "\n",
    "    if sentence2:\n",
    "        response = sentence2\n",
    "    else:\n",
    "        if emotion == \"sad\":\n",
    "            response = \"I hear that you're going through a really difficult time right now. Those feelings are valid, and you're not alone. Would you like to talk about what's been making you feel this way?\"\n",
    "        elif emotion == \"anxious\":\n",
    "            response = \"It sounds like you're dealing with some anxiety, which can be really challenging. These feelings are completely normal. What specifically has been making you feel anxious?\"\n",
    "        elif emotion == \"angry\":\n",
    "            response = \"I can hear the frustration and anger in what you're sharing. These feelings are completely understandable. Sometimes it helps to talk about what's been making you feel this way.\"\n",
    "        elif emotion == \"confused\":\n",
    "            response = \"That's a really important question about relationships and growing up. These feelings of confusion are normal during adolescence. Let's explore this together.\"\n",
    "        elif emotion == \"curious\":\n",
    "            response = \"That's a great question about personal growth! It shows you're thinking deeply about your development. Let's discuss what this means for you.\"\n",
    "        else:\n",
    "            response = \"Thank you for sharing that with me. I appreciate your thoughtfulness. Let's discuss this further.\"\n",
    "\n",
    "    extended_data.append({\n",
    "        \"text\": sentence1,\n",
    "        \"emotion\": emotion,\n",
    "        \"intent\": intent,\n",
    "        \"response\": response\n",
    "    })\n",
    "\n",
    "for item in causal_lm_data:\n",
    "    text = item.get('text', '')\n",
    "\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # predict intent and emotion for causal LM data\n",
    "    if any(word in text_lower for word in ['?', 'why', 'how', 'what']):\n",
    "        intent = \"question\"\n",
    "    else:\n",
    "        intent = \"seeking support\"\n",
    "\n",
    "    if any(word in text_lower for word in ['autonomy', 'independence', 'mother', 'father']):\n",
    "        emotion = \"confused\"\n",
    "        response = \"That's an important question about family relationships and independence. Let's explore this together.\"\n",
    "    elif any(word in text_lower for word in ['growth', 'personal', 'development']):\n",
    "        emotion = \"curious\"\n",
    "        response = \"Personal growth is a key part of adolescent development. It shows you're developing self-awareness.\"\n",
    "    elif any(word in text_lower for word in ['purpose', 'life', 'meaning']):\n",
    "        emotion = \"thoughtful\"\n",
    "        response = \"Having a sense of purpose is crucial for well-being. It gives direction and meaning to your experiences.\"\n",
    "    else:\n",
    "        emotion = \"thoughtful\"\n",
    "        response = \"That's a thoughtful question. Let's discuss this in more detail.\"\n",
    "\n",
    "    extended_data.append({\n",
    "        \"text\": text,\n",
    "        \"emotion\": emotion,\n",
    "        \"intent\": intent,\n",
    "        \"response\": response\n",
    "    })\n",
    "\n",
    "# training examples for better understanding and emotion detection\n",
    "additional_examples = [\n",
    "    {\n",
    "        \"text\": \"I feel like nobody likes me at school and I'm always alone\",\n",
    "        \"emotion\": \"sad\",\n",
    "        \"intent\": \"venting\",\n",
    "        \"response\": \"I'm really sorry you're feeling so alone at school. That sense of isolation can be really painful. Your feelings are completely valid, and I want you to know that you matter.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Why do I always feel worthless and like I can't do anything right\",\n",
    "        \"emotion\": \"sad\",\n",
    "        \"intent\": \"question\",\n",
    "        \"response\": \"Those feelings of worthlessness are really hard to carry. It's important to know that these thoughts don't reflect your true value as a person. You're asking a brave question by reaching out.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"How can I deal with my anxiety it's getting really bad\",\n",
    "        \"emotion\": \"anxious\",\n",
    "        \"intent\": \"seeking support\",\n",
    "        \"response\": \"I'm glad you're reaching out about your anxiety. That takes courage. There are definitely strategies that can help manage anxiety. Let's work through some techniques together.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I'm so angry at my parents they never listen to me\",\n",
    "        \"emotion\": \"angry\",\n",
    "        \"intent\": \"venting\",\n",
    "        \"response\": \"It's really frustrating when you feel like your parents aren't hearing you. Those angry feelings make complete sense when you don't feel understood or respected.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I can't stop overthinking everything and it's making me crazy\",\n",
    "        \"emotion\": \"anxious\",\n",
    "        \"intent\": \"venting\",\n",
    "        \"response\": \"That constant overthinking sounds exhausting. When our minds race like that, it can feel overwhelming. You're not alone in experiencing this.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Why do I feel so hopeless about everything\",\n",
    "        \"emotion\": \"sad\",\n",
    "        \"intent\": \"question\",\n",
    "        \"response\": \"Feeling hopeless can be incredibly heavy and difficult to bear. These feelings are telling me that you're really struggling right now. What's been contributing to these feelings?\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I feel empty inside like nothing matters anymore\",\n",
    "        \"emotion\": \"sad\",\n",
    "        \"intent\": \"venting\",\n",
    "        \"response\": \"That emptiness you're describing sounds really painful. When everything feels meaningless, it can be so isolating. I'm here to listen and help you work through these feelings.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"I hate myself for being such a failure\",\n",
    "        \"emotion\": \"sad\",\n",
    "        \"intent\": \"venting\",\n",
    "        \"response\": \"I hear so much pain in what you're sharing. Those harsh thoughts about yourself must be exhausting to carry. You're not a failure - you're a person going through a difficult time.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Everything makes me worry and I can't relax\",\n",
    "        \"emotion\": \"anxious\",\n",
    "        \"intent\": \"venting\",\n",
    "        \"response\": \"Living with that constant worry sounds really exhausting. When anxiety affects our ability to relax, it can feel overwhelming. Let's talk about what's been triggering these worries.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "extended_data.extend(additional_examples)\n",
    "\n",
    "labels_emotion = list(set(d['emotion'] for d in extended_data))\n",
    "labels_intent = list(set(d['intent'] for d in extended_data))\n",
    "\n",
    "print(f\"Total samples: {len(extended_data)}\")\n",
    "print(f\"Emotion labels ({len(labels_emotion)}): {labels_emotion}\")\n",
    "print(f\"Intent labels ({len(labels_intent)}): {labels_intent}\")\n",
    "\n",
    "for d in extended_data:\n",
    "    d['emotion_label'] = labels_emotion.index(d['emotion'])\n",
    "    d['intent_label'] = labels_intent.index(d['intent'])\n",
    "\n",
    "# train-test split and dataset conversion\n",
    "train_data, test_data = train_test_split(extended_data, test_size=0.15, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame(train_data))\n",
    "test_dataset = Dataset.from_pandas(pd.DataFrame(test_data))\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "print(\"\\nSample training data:\")\n",
    "for i in range(min(3, len(train_data))):\n",
    "    sample = train_data[i]\n",
    "    print(f\"Text: {sample['text'][:80]}...\")\n",
    "    print(f\"Emotion: {sample['emotion']}, Intent: {sample['intent']}\")\n",
    "    print(f\"Response: {sample['response'][:80]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2903f267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b99ebb0e775459aad67bff834719af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b721bf8379a0438bb7cb3444f332a8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/182 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7886/3845594068.py:37: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ELECTRA classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1285' max='1285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1285/1285 00:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.060861</td>\n",
       "      <td>0.989011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>0.989011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.989011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.994505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.994505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.016262898221611977, 'eval_accuracy': 0.9945054945054945, 'eval_runtime': 0.3841, 'eval_samples_per_second': 473.778, 'eval_steps_per_second': 119.746, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./electra_emotion_classifier/tokenizer_config.json',\n",
       " './electra_emotion_classifier/special_tokens_map.json',\n",
       " './electra_emotion_classifier/vocab.txt',\n",
       " './electra_emotion_classifier/added_tokens.json',\n",
       " './electra_emotion_classifier/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# electra classifier for emotion and intent prediction\n",
    "\n",
    "classifier_model = ElectraForSequenceClassification.from_pretrained(\n",
    "    \"google/electra-small-discriminator\",\n",
    "    num_labels=len(labels_emotion)\n",
    ")\n",
    "classifier_tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-small-discriminator\")\n",
    "\n",
    "def tokenize_and_encode(batch):\n",
    "    return classifier_tokenizer(batch['text'], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# tokenization of datasets\n",
    "train_tokenized = train_dataset.map(tokenize_and_encode, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_and_encode, batched=True)\n",
    "\n",
    "train_tokenized = train_tokenized.rename_column(\"emotion_label\", \"labels\")\n",
    "test_tokenized = test_tokenized.rename_column(\"emotion_label\", \"labels\")\n",
    "\n",
    "train_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# training arguments\n",
    "classifier_args = TrainingArguments(\n",
    "    output_dir=\"./classifier_output\",\n",
    "    logging_steps=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    seed=42,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(\n",
    "    model=classifier_model,\n",
    "    args=classifier_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=classifier_tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=classifier_tokenizer),\n",
    "    compute_metrics=lambda p: {\n",
    "        \"accuracy\": accuracy_score(\n",
    "            p.label_ids, np.argmax(p.predictions, axis=1)\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Training ELECTRA classifier...\")\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "classifier_model.save_pretrained(\"./electra_emotion_classifier\")\n",
    "classifier_tokenizer.save_pretrained(\"./electra_emotion_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d53f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing GPT-2 training data...\n",
      "Total GPT-2 training samples: 1209\n",
      "GPT-2 training samples: 1088\n",
      "GPT-2 test samples: 121\n",
      "GPT-2 training samples: 1088\n",
      "GPT-2 test samples: 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a328b407cd4ab89368f9fcc496867d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeeec46741e4d918841e1a72d85b253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/121 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7886/1470145640.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  gpt_trainer = Trainer(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GPT-2 response generator...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='680' max='680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [680/680 05:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.025999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.025878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.024932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.025138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 evaluation results: {'eval_loss': 0.024932222440838814, 'eval_runtime': 1.3623, 'eval_samples_per_second': 88.823, 'eval_steps_per_second': 44.778, 'epoch': 5.0}\n",
      "GPT-2 Perplexity: 1.03\n",
      "GPT-2 Evaluation Loss: 0.0249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./gpt2_adolescent_chatbot_final/tokenizer_config.json',\n",
       " './gpt2_adolescent_chatbot_final/special_tokens_map.json',\n",
       " './gpt2_adolescent_chatbot_final/vocab.json',\n",
       " './gpt2_adolescent_chatbot_final/merges.txt',\n",
       " './gpt2_adolescent_chatbot_final/added_tokens.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training for gpt2\n",
    "print(\"Preparing GPT-2 training data...\")\n",
    "\n",
    "prompted_samples = []\n",
    "\n",
    "for d in extended_data:\n",
    "    prompted_samples.append({\n",
    "        \"input\": f\"emotion: {d['emotion']}, intent: {d['intent']}\\nUser: {d['text']}\\nAssistant:\",\n",
    "        \"output\": d['response']\n",
    "    })\n",
    "\n",
    "print(f\"Total GPT-2 training samples: {len(prompted_samples)}\")\n",
    "\n",
    "# model loading\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "def encode_gpt(example):\n",
    "    prompt = example['input']\n",
    "    response = example['output']\n",
    "\n",
    "    # Create a more focused training format\n",
    "    full_text = f\"{prompt} {response}<|endoftext|>\"\n",
    "\n",
    "    encoding = gpt_tokenizer(\n",
    "        full_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # labels for causal language modeling\n",
    "    labels = encoding[\"input_ids\"].clone()\n",
    "\n",
    "    # Find where the assistant response starts to focus training\n",
    "    prompt_tokens = gpt_tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
    "    prompt_length = len(prompt_tokens)\n",
    "\n",
    "    # Mask the prompt part so model focuses on learning responses\n",
    "    if prompt_length < labels.shape[1]:\n",
    "        labels[0, :prompt_length] = -100\n",
    "\n",
    "    encoding[\"labels\"] = labels.squeeze(0)\n",
    "    return {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "\n",
    "# dataset to train and split\n",
    "gpt_train_data, gpt_test_data = train_test_split(prompted_samples, test_size=0.1, random_state=42)\n",
    "\n",
    "gpt_train_dataset = Dataset.from_list(gpt_train_data)\n",
    "gpt_test_dataset = Dataset.from_list(gpt_test_data)\n",
    "\n",
    "print(f\"GPT-2 training samples: {len(gpt_train_dataset)}\")\n",
    "print(f\"GPT-2 test samples: {len(gpt_test_dataset)}\")\n",
    "\n",
    "gpt_train_dataset = gpt_train_dataset.map(encode_gpt)\n",
    "gpt_test_dataset = gpt_test_dataset.map(encode_gpt)\n",
    "\n",
    "gpt_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "gpt_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# training arguments for GPT-2\n",
    "gpt_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_response_generator\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "# trainer\n",
    "gpt_trainer = Trainer(\n",
    "    model=gpt_model,\n",
    "    args=gpt_args,\n",
    "    train_dataset=gpt_train_dataset,\n",
    "    eval_dataset=gpt_test_dataset,\n",
    "    tokenizer=gpt_tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(gpt_tokenizer, padding=True)\n",
    ")\n",
    "\n",
    "print(\"Training GPT-2 response generator...\")\n",
    "gpt_trainer.train()\n",
    "gpt_eval_results = gpt_trainer.evaluate()\n",
    "print(f\"GPT-2 evaluation results: {gpt_eval_results}\")\n",
    "\n",
    "# Calculate perplexity for better evaluation of generative model\n",
    "import math\n",
    "eval_loss = gpt_eval_results['eval_loss']\n",
    "perplexity = math.exp(eval_loss)\n",
    "print(f\"GPT-2 Perplexity: {perplexity:.2f}\")\n",
    "print(f\"GPT-2 Evaluation Loss: {eval_loss:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "gpt_model.save_pretrained(\"./gpt2_adolescent_chatbot_final\")\n",
    "gpt_tokenizer.save_pretrained(\"./gpt2_adolescent_chatbot_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d098b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Two-Model Chatbot Architecture\n",
      "==================================================\n",
      "\n",
      " Test 1: I feel like nobody likes me at school.\n",
      "------------------------------\n",
      "Emotion Detected: sad (confidence: 0.27)\n",
      "Assistant Response: That's true! In fact, the most common response you hear is \"I'm not really that into academics.\" This may be a result of an individual feeling isolated or ignored by their peers.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.083\n",
      "   thoughtful: 0.090\n",
      "   curious: 0.067\n",
      "   anxious: 0.251\n",
      "   sad: 0.272\n",
      "   angry: 0.237\n",
      "\n",
      " Test 2: Why do I always feel worthless?\n",
      "------------------------------\n",
      "Emotion Detected: sad (confidence: 0.27)\n",
      "Assistant Response: That's true! In fact, the most common response you hear is \"I'm not really that into academics.\" This may be a result of an individual feeling isolated or ignored by their peers.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.083\n",
      "   thoughtful: 0.090\n",
      "   curious: 0.067\n",
      "   anxious: 0.251\n",
      "   sad: 0.272\n",
      "   angry: 0.237\n",
      "\n",
      " Test 2: Why do I always feel worthless?\n",
      "------------------------------\n",
      "Emotion Detected: sad (confidence: 0.27)\n",
      "Assistant Response: In this case the respondent scored 34 on purpose in life. This reflects their sense of goal direction, motivation and future orientation during adolescence.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.097\n",
      "   thoughtful: 0.086\n",
      "   curious: 0.063\n",
      "   anxious: 0.245\n",
      "   sad: 0.274\n",
      "   angry: 0.235\n",
      "\n",
      " Test 3: How can I deal with my anxiety?\n",
      "------------------------------\n",
      "Emotion Detected: confused (confidence: 0.77)\n",
      "Assistant Response: In this case the respondent scored 22 on mental health. This reflects their sense of goal direction and motivation during adolescence.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.768\n",
      "   thoughtful: 0.023\n",
      "   curious: 0.016\n",
      "   anxious: 0.062\n",
      "   sad: 0.069\n",
      "   angry: 0.062\n",
      "\n",
      " Test 4: I'm angry at my parents for not understanding me.\n",
      "------------------------------\n",
      "Emotion Detected: sad (confidence: 0.27)\n",
      "Assistant Response: In this case the respondent scored 34 on purpose in life. This reflects their sense of goal direction, motivation and future orientation during adolescence.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.097\n",
      "   thoughtful: 0.086\n",
      "   curious: 0.063\n",
      "   anxious: 0.245\n",
      "   sad: 0.274\n",
      "   angry: 0.235\n",
      "\n",
      " Test 3: How can I deal with my anxiety?\n",
      "------------------------------\n",
      "Emotion Detected: confused (confidence: 0.77)\n",
      "Assistant Response: In this case the respondent scored 22 on mental health. This reflects their sense of goal direction and motivation during adolescence.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.768\n",
      "   thoughtful: 0.023\n",
      "   curious: 0.016\n",
      "   anxious: 0.062\n",
      "   sad: 0.069\n",
      "   angry: 0.062\n",
      "\n",
      " Test 4: I'm angry at my parents for not understanding me.\n",
      "------------------------------\n",
      "Emotion Detected: sad (confidence: 0.27)\n",
      "Assistant Response: That's a tough one to bear when you're so emotionally charged and dependent on someone else for your well-being. It gives the impression that everything is going poorly or being manipulated by an unseen authority figure in control of how things turn out.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.077\n",
      "   thoughtful: 0.085\n",
      "   curious: 0.069\n",
      "   anxious: 0.257\n",
      "   sad: 0.270\n",
      "   angry: 0.243\n",
      "\n",
      " Test 5: What does personal growth mean for teenagers?\n",
      "------------------------------\n",
      "Emotion Detected: curious (confidence: 1.00)\n",
      "Assistant Response: Personal development is a key part of adolescent success. It shows you're developing self-awareness.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.001\n",
      "   thoughtful: 0.001\n",
      "   curious: 0.997\n",
      "   anxious: 0.000\n",
      "   sad: 0.000\n",
      "   angry: 0.000\n",
      "\n",
      " Test 6: How does my relationship with my mother affect my independence?\n",
      "------------------------------\n",
      "Emotion Detected: sad (confidence: 0.27)\n",
      "Assistant Response: That's a tough one to bear when you're so emotionally charged and dependent on someone else for your well-being. It gives the impression that everything is going poorly or being manipulated by an unseen authority figure in control of how things turn out.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.077\n",
      "   thoughtful: 0.085\n",
      "   curious: 0.069\n",
      "   anxious: 0.257\n",
      "   sad: 0.270\n",
      "   angry: 0.243\n",
      "\n",
      " Test 5: What does personal growth mean for teenagers?\n",
      "------------------------------\n",
      "Emotion Detected: curious (confidence: 1.00)\n",
      "Assistant Response: Personal development is a key part of adolescent success. It shows you're developing self-awareness.\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.001\n",
      "   thoughtful: 0.001\n",
      "   curious: 0.997\n",
      "   anxious: 0.000\n",
      "   sad: 0.000\n",
      "   angry: 0.000\n",
      "\n",
      " Test 6: How does my relationship with my mother affect my independence?\n",
      "------------------------------\n",
      "Emotion Detected: confused (confidence: 1.00)\n",
      "Assistant Response: In this case the respondent scored 25 for maternal support and 26 on independent corroboration. This suggests that perceived paternal influence may be related to how independently the adolescent feels they can make decisions\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.999\n",
      "   thoughtful: 0.000\n",
      "   curious: 0.000\n",
      "   anxious: 0.000\n",
      "   sad: 0.000\n",
      "   angry: 0.000\n",
      "\n",
      "==================================================\n",
      "Model Evaluation on Test Set\n",
      "==================================================\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: What does a high personal growth score mean during...\n",
      "Actual: curious | Predicted: curious | Correct\n",
      "\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: What does a high personal growth score mean during...\n",
      "Actual: curious | Predicted: curious | Correct\n",
      "\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Classification Accuracy: 1.00 (10/10)\n",
      "Emotion Detected: confused (confidence: 1.00)\n",
      "Assistant Response: In this case the respondent scored 25 for maternal support and 26 on independent corroboration. This suggests that perceived paternal influence may be related to how independently the adolescent feels they can make decisions\n",
      "\n",
      "Emotion Analysis:\n",
      "   confused: 0.999\n",
      "   thoughtful: 0.000\n",
      "   curious: 0.000\n",
      "   anxious: 0.000\n",
      "   sad: 0.000\n",
      "   angry: 0.000\n",
      "\n",
      "==================================================\n",
      "Model Evaluation on Test Set\n",
      "==================================================\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: What does a high personal growth score mean during...\n",
      "Actual: curious | Predicted: curious | Correct\n",
      "\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: How does your relationship with your mother affect...\n",
      "Actual: confused | Predicted: confused | Correct\n",
      "\n",
      "Text: What does a high personal growth score mean during...\n",
      "Actual: curious | Predicted: curious | Correct\n",
      "\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Text: Why is purpose in life important for teenagers?...\n",
      "Actual: thoughtful | Predicted: thoughtful | Correct\n",
      "\n",
      "Classification Accuracy: 1.00 (10/10)\n"
     ]
    }
   ],
   "source": [
    "# Inference Functions for Two-Model Chatbot Architecture\n",
    "\n",
    "def classify_emotion_intent(text):\n",
    "\n",
    "    # Electra model loading to the device\n",
    "    device = next(classifier_model.parameters()).device\n",
    "\n",
    "    inputs = classifier_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    classifier_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier_model(**inputs)\n",
    "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "        confidence = torch.softmax(outputs.logits, dim=1).max().item()\n",
    "\n",
    "    return {\n",
    "        \"emotion\": labels_emotion[pred],\n",
    "        \"confidence\": confidence,\n",
    "        \"all_scores\": {labels_emotion[i]: score.item() for i, score in enumerate(torch.softmax(outputs.logits, dim=1)[0])}\n",
    "    }\n",
    "\n",
    "def generate_response(text, max_length=80, temperature=0.8):\n",
    "    # gpt2 model loading to the device\n",
    "    classification = classify_emotion_intent(text)\n",
    "    emotion = classification[\"emotion\"]\n",
    "\n",
    "    # Determine intent from the text for better prompting\n",
    "    text_lower = text.lower()\n",
    "    if any(word in text_lower for word in ['why', 'how', 'what', 'when', 'where']):\n",
    "        intent = \"question\"\n",
    "    elif any(word in text_lower for word in ['help', 'deal with', 'handle', 'support']):\n",
    "        intent = \"seeking support\"\n",
    "    else:\n",
    "        intent = \"venting\"\n",
    "\n",
    "    # Create a more specific prompt for better responses\n",
    "    prompt = f\"emotion: {emotion}, intent: {intent}\\nUser: {text}\\nAssistant:\"\n",
    "\n",
    "    device = next(gpt_model.parameters()).device\n",
    "\n",
    "    # generate response with better parameters\n",
    "    input_ids = gpt_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    gpt_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = gpt_model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,  # Nucleus sampling for better quality\n",
    "            top_k=50,   # Top-k sampling\n",
    "            pad_token_id=gpt_tokenizer.pad_token_id,\n",
    "            eos_token_id=gpt_tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.2,  # Reduce repetition\n",
    "            no_repeat_ngram_size=3   # Avoid repeating 3-grams\n",
    "        )\n",
    "\n",
    "    full_response = gpt_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract only the assistant's response\n",
    "    if \"Assistant:\" in full_response:\n",
    "        assistant_response = full_response.split(\"Assistant:\")[-1].strip()\n",
    "    else:\n",
    "        assistant_response = \"I understand you're going through something difficult. Can you tell me more about how you're feeling?\"\n",
    "\n",
    "    # Clean up the response\n",
    "    assistant_response = assistant_response.replace(\"<|endoftext|>\", \"\").strip()\n",
    "\n",
    "    # If response is too short or generic, provide a fallback\n",
    "    if len(assistant_response) < 10 or assistant_response in [\"\", \" \"]:\n",
    "        if emotion == \"sad\":\n",
    "            assistant_response = \"I can hear that you're really struggling right now. Those feelings are completely valid. What's been weighing on your mind?\"\n",
    "        elif emotion == \"anxious\":\n",
    "            assistant_response = \"It sounds like you're dealing with some anxiety. That can be really overwhelming. Would you like to talk about what's been making you feel this way?\"\n",
    "        elif emotion == \"angry\":\n",
    "            assistant_response = \"I can sense your frustration. Those feelings are completely understandable. What's been making you feel this way?\"\n",
    "        else:\n",
    "            assistant_response = \"Thank you for sharing that with me. I'd like to understand better - can you tell me more about what you're experiencing?\"\n",
    "\n",
    "    return {\n",
    "        \"response\": assistant_response,\n",
    "        \"emotion_detected\": emotion,\n",
    "        \"confidence\": classification[\"confidence\"],\n",
    "        \"emotion_scores\": classification[\"all_scores\"]\n",
    "    }\n",
    "\n",
    "# Testing\n",
    "print(\"Testing Two-Model Chatbot Architecture\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_inputs = [\n",
    "    \"I feel like nobody likes me at school.\",\n",
    "    \"Why do I always feel worthless?\",\n",
    "    \"How can I deal with my anxiety?\",\n",
    "    \"I'm angry at my parents for not understanding me.\",\n",
    "    \"What does personal growth mean for teenagers?\",\n",
    "    \"How does my relationship with my mother affect my independence?\"\n",
    "]\n",
    "\n",
    "for i, user_input in enumerate(test_inputs, 1):\n",
    "    print(f\"\\n Test {i}: {user_input}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    result = generate_response(user_input)\n",
    "\n",
    "    print(f\"Emotion Detected: {result['emotion_detected']} (confidence: {result['confidence']:.2f})\")\n",
    "    print(f\"Assistant Response: {result['response']}\")\n",
    "\n",
    "    print(f\"\\nEmotion Analysis:\")\n",
    "    for emotion, score in result['emotion_scores'].items():\n",
    "        print(f\"   {emotion}: {score:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Model Evaluation on Test Set\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for item in test_data[:10]:\n",
    "    prediction = classify_emotion_intent(item['text'])\n",
    "    actual_emotion = item['emotion']\n",
    "    predicted_emotion = prediction['emotion']\n",
    "\n",
    "    if predicted_emotion == actual_emotion:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "    print(f\"Text: {item['text'][:50]}...\")\n",
    "    print(f\"Actual: {actual_emotion} | Predicted: {predicted_emotion} | {'Correct' if predicted_emotion == actual_emotion else 'Wrong'}\")\n",
    "    print()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Classification Accuracy: {accuracy:.2f} ({correct_predictions}/{total_predictions})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b407394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the chatbot with your own questions on different topics!\n",
      "Type 'quit' to exit\n",
      "--------------------------------------------------\n",
      "\n",
      "Testing with diverse questions first:\n",
      "==================================================\n",
      "\n",
      "Test 1: I'm having trouble sleeping because I keep thinking about my future\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's not a good sign. It shows you're struggling with your thoughts.\n",
      "\n",
      "Test 2: My friends seem to be moving on without me and I feel left behind\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's not a good sign. It shows you're struggling with your thoughts.\n",
      "\n",
      "Test 2: My friends seem to be moving on without me and I feel left behind\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's not true. Those of us who're together can make a difference in the world.\n",
      "\n",
      "Test 3: I don't know what I want to do with my life and it scares me\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's not true. Those of us who're together can make a difference in the world.\n",
      "\n",
      "Test 3: I don't know what I want to do with my life and it scares me\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: Having a sense of purpose is crucial for well-being. It gives direction or meaning when you're struggling.\n",
      "\n",
      "Test 4: I feel pressure to be perfect all the time\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: Having a sense of purpose is crucial for well-being. It gives direction or meaning when you're struggling.\n",
      "\n",
      "Test 4: I feel pressure to be perfect all the time\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's a tough one. You're not supposed for perfection but you can make it better by sharing your successes and failures with others.\n",
      "\n",
      "Test 5: I'm struggling with my identity and who I really am\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's an important part of being a person. It shows you're genuinely thinking about yourself every day\n",
      "\n",
      "Test 6: I feel like I'm not good enough compared to others on social media\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's a tough one. You're not supposed for perfection but you can make it better by sharing your successes and failures with others.\n",
      "\n",
      "Test 5: I'm struggling with my identity and who I really am\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: That's an important part of being a person. It shows you're genuinely thinking about yourself every day\n",
      "\n",
      "Test 6: I feel like I'm not good enough compared to others on social media\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: In this case there was a strong sense of entitlement towards certain aspects or experiences. This suggests that perceived self-loathing may be related in part (or even all) by nature - as opposed for the other person to attribute these feelings to their own failings.\n",
      "\n",
      "Test 7: I'm worried about climate change and the future of the world\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: In this case there was a strong sense of entitlement towards certain aspects or experiences. This suggests that perceived self-loathing may be related in part (or even all) by nature - as opposed for the other person to attribute these feelings to their own failings.\n",
      "\n",
      "Test 7: I'm worried about climate change and the future of the world\n",
      "------------------------------\n",
      "Emotion: sad (0.26)\n",
      "Response: That worries me a lot. It's really frustrating when people assume that what they're hearing sounds positive or optimistic — but it can be incredibly harmful for your well-being. Let's explore this together to make sure you stay focused on helping yourself feel better\n",
      "\n",
      "Test 8: I feel like my teachers don't understand me\n",
      "------------------------------\n",
      "Emotion: sad (0.26)\n",
      "Response: That worries me a lot. It's really frustrating when people assume that what they're hearing sounds positive or optimistic — but it can be incredibly harmful for your well-being. Let's explore this together to make sure you stay focused on helping yourself feel better\n",
      "\n",
      "Test 8: I feel like my teachers don't understand me\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: In this case, the teacher scored 29 on reflection. This reflects her sense of goal direction, motivation and future orientation during adolescence.\n",
      "\n",
      "Test 9: I'm having conflicts with my siblings\n",
      "------------------------------\n",
      "Emotion: sad (0.27)\n",
      "Response: In this case, the teacher scored 29 on reflection. This reflects her sense of goal direction, motivation and future orientation during adolescence.\n",
      "\n",
      "Test 9: I'm having conflicts with my siblings\n",
      "------------------------------\n",
      "Emotion: sad (0.26)\n",
      "Response: That's not a conflict of interest. You're making decisions based on the experiences you've had and how they affected your relationships.\n",
      "\n",
      "Test 10: I feel overwhelmed by all the expectations people have of me\n",
      "------------------------------\n",
      "Emotion: sad (0.28)\n",
      "Response: That's not a surprise to hear. It shows you're capable and ready to take on new challenges\n",
      "\n",
      "==================================================\n",
      "Now you can test with your own questions!\n",
      "Try asking about topics like:\n",
      "- Relationships and friendships\n",
      "- School and academic pressure\n",
      "- Future career concerns\n",
      "- Social media and self-image\n",
      "- Family dynamics\n",
      "- Personal growth and identity\n",
      "- Mental health and coping\n",
      "==================================================\n",
      "Emotion: sad (0.26)\n",
      "Response: That's not a conflict of interest. You're making decisions based on the experiences you've had and how they affected your relationships.\n",
      "\n",
      "Test 10: I feel overwhelmed by all the expectations people have of me\n",
      "------------------------------\n",
      "Emotion: sad (0.28)\n",
      "Response: That's not a surprise to hear. It shows you're capable and ready to take on new challenges\n",
      "\n",
      "==================================================\n",
      "Now you can test with your own questions!\n",
      "Try asking about topics like:\n",
      "- Relationships and friendships\n",
      "- School and academic pressure\n",
      "- Future career concerns\n",
      "- Social media and self-image\n",
      "- Family dynamics\n",
      "- Personal growth and identity\n",
      "- Mental health and coping\n",
      "==================================================\n",
      "Thanks for testing! Goodbye!\n",
      "Thanks for testing! Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Interactive Testing Cell - Test Your Own Questions\n",
    "print(\"Test the chatbot with your own questions on different topics!\")\n",
    "print(\"Type 'quit' to exit\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def interactive_chat():\n",
    "    while True:\n",
    "        user_input = input(\"\\nYour question: \")\n",
    "\n",
    "        if user_input.lower() in ['quit', 'exit', 'stop']:\n",
    "            print(\"Thanks for testing! Goodbye!\")\n",
    "            break\n",
    "\n",
    "        if not user_input.strip():\n",
    "            print(\"Please enter a question.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing: '{user_input}'\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        try:\n",
    "            # Get the response from our chatbot\n",
    "            result = generate_response(user_input)\n",
    "\n",
    "            print(f\"Emotion Detected: {result['emotion_detected']} (confidence: {result['confidence']:.2f})\")\n",
    "            print(f\"Assistant Response: {result['response']}\")\n",
    "\n",
    "            print(f\"\\nDetailed Emotion Analysis:\")\n",
    "            sorted_emotions = sorted(result['emotion_scores'].items(), key=lambda x: x[1], reverse=True)\n",
    "            for emotion, score in sorted_emotions:\n",
    "                bar = \"||\" * int(score * 20)  # Visual bar\n",
    "                print(f\"   {emotion:>10}: {score:.3f} {bar}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {str(e)}\")\n",
    "            print(\"Please try a different question.\")\n",
    "\n",
    "# Test with some diverse questions first\n",
    "test_questions = [\n",
    "    \"I'm having trouble sleeping because I keep thinking about my future\",\n",
    "    \"My friends seem to be moving on without me and I feel left behind\",\n",
    "    \"I don't know what I want to do with my life and it scares me\",\n",
    "    \"I feel pressure to be perfect all the time\",\n",
    "    \"I'm struggling with my identity and who I really am\",\n",
    "    \"I feel like I'm not good enough compared to others on social media\",\n",
    "    \"I'm worried about climate change and the future of the world\",\n",
    "    \"I feel like my teachers don't understand me\",\n",
    "    \"I'm having conflicts with my siblings\",\n",
    "    \"I feel overwhelmed by all the expectations people have of me\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting with diverse questions first:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nTest {i}: {question}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    try:\n",
    "        result = generate_response(question)\n",
    "        print(f\"Emotion: {result['emotion_detected']} ({result['confidence']:.2f})\")\n",
    "        print(f\"Response: {result['response']}\")\n",
    "\n",
    "        # Check if response is too generic/repetitive\n",
    "        generic_phrases = [\n",
    "            \"That's true! In fact\",\n",
    "            \"the most common response\",\n",
    "            \"not really that into academics\"\n",
    "        ]\n",
    "\n",
    "        is_generic = any(phrase in result['response'] for phrase in generic_phrases)\n",
    "        if is_generic:\n",
    "            print(\"WARNING: Response appears to be generic/repetitive\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Now you can test with your own questions!\")\n",
    "print(\"Try asking about topics like:\")\n",
    "print(\"- Relationships and friendships\")\n",
    "print(\"- School and academic pressure\")\n",
    "print(\"- Future career concerns\")\n",
    "print(\"- Social media and self-image\")\n",
    "print(\"- Family dynamics\")\n",
    "print(\"- Personal growth and identity\")\n",
    "print(\"- Mental health and coping\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72eb9f",
   "metadata": {},
   "source": [
    "Electra performance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f624fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_electra_performance():\n",
    "    print(\"Electra emotion and intent classifier performance\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    prediction = []\n",
    "    true_labels = []\n",
    "    confidence = []\n",
    "\n",
    "    classifier_model.eval()\n",
    "    for item in test_data:\n",
    "        result = classify_emotion_intent(item['text'])\n",
    "        prediction.append(result['emotion'])\n",
    "        true_labels.append(item['emotion'])\n",
    "        confidence.append(result['confidence'])\n",
    "\n",
    "    # convertion to label index for metrics\n",
    "    pred_indices = [labels_emotion.index(pred) for pred in prediction]\n",
    "    true_indices = [labels_emotion.index(true) for true in true_labels]\n",
    "\n",
    "    # metrics calculation\n",
    "    accuracy = accuracy_score(true_indices, pred_indices)\n",
    "    precision, recall, fl, support = precision_recall_fscore_support(true_indices, pred_indices, average='weighted')\n",
    "\n",
    "    print(f\"Overall accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted precision: {precision:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall:.4f}\")\n",
    "    print(f\"Weighted Fl_Score: {fl:.4f}\")\n",
    "    print(f\"Average Confidence: {np.mean(confidence):.4f}\")\n",
    "\n",
    "    print(\"/nPer-class Performance:\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    class_report = classification_report(\n",
    "        true_indices, pred_indices,\n",
    "        target_names=labels_emotion,\n",
    "        output_dict=True,\n",
    "    )\n",
    "\n",
    "    for emotion in labels_emotion:\n",
    "        metrics = class_report[emotion]\n",
    "        print(f\"{emotion:>10}: P={metrics['precision']:.3f}, R={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}\")\n",
    "\n",
    "    # confusion metrics\n",
    "    cm = confusion_matrix(true_indices, pred_indices)\n",
    "    print(f\"\\nConfusion matrix:\")\n",
    "    print(\"Actual\\\\Predicted\", end=\"\")\n",
    "    for emotion in labels_emotion:\n",
    "        print(f\"{emotion:>8}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "    for i, emotion in enumerate(labels_emotion):\n",
    "        print(f\"{emotion:>12}\", end=\"\")\n",
    "        for j in range(len(labels_emotion)):\n",
    "            print(f\"{cm[i, j]:>8}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'avg_confidence': np.mean(confidence),\n",
    "        'confusion_matrix': cm,\n",
    "        'class_report': class_report\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cdb24b",
   "metadata": {},
   "source": [
    "GPT-2 performance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gpt2_performance():\n",
    "    print(\"GPT-2 Performance\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    if 'gpt_eval_results' in globals():\n",
    "        eval_loss = gpt_eval_results['eval_loss']\n",
    "        perplexity = math.exp(eval_loss)\n",
    "        print(f\"Perplexity: {perplexity:.2f}\")\n",
    "        print(f\"Evaluation loss: {eval_loss:.4f}\")\n",
    "\n",
    "    # response quality metrics\n",
    "    response_length = []\n",
    "    response_diversity = set()\n",
    "    appropriate_response = 0\n",
    "    total_response = 0\n",
    "\n",
    "    test_sample = test_data[:20]\n",
    "\n",
    "    print(\"\\nResponse Quality Analysis:\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    for item in test_sample:\n",
    "        result = generate_response(item['text'], max_length=60)\n",
    "        response =  result['response']\n",
    "\n",
    "        # response length\n",
    "        response_length.append(len(response.split()))\n",
    "        response_diversity.add(response)\n",
    "\n",
    "        # basic heuristics\n",
    "        is_appropriate = (\n",
    "            len(response.split()) >= 5 and\n",
    "            len(response.split()) <= 100 and\n",
    "            not any(phrase in response.lower() for phrase in ['i don\\'t know', 'sorry, i can\\'t'])and\n",
    "            any(word in response.lower() for word in ['feel', 'understand', 'help', 'support', 'you'])\n",
    "        )\n",
    "\n",
    "        if is_appropriate:\n",
    "            appropriate_responses += 1\n",
    "        total_responses += 1\n",
    "\n",
    "        print(f\"Input: {item['text'][:50]}...\")\n",
    "        print(f\"Response: {response[:80]}...\")\n",
    "        print(f\"Length: {len(response.split())} words | Appropriate: {'Yes' if is_appropriate else 'No'}\")\n",
    "        print()\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_length = np.mean(response_length)\n",
    "    diversity_ratio = len(response_diversity) / len(test_sample)\n",
    "    appropriateness_rate = appropriate_responses / total_responses\n",
    "\n",
    "    print(f\"Average Response Length: {avg_length:.1f} words\")\n",
    "    print(f\"Response Diversity Ratio: {diversity_ratio:.3f}\")\n",
    "    print(f\"Appropriateness Rate: {appropriateness_rate:.3f}\")\n",
    "\n",
    "    return {\n",
    "        'perplexity': perplexity if 'gpt_eval_results' in globals() else None,\n",
    "        'avg_length': avg_length,\n",
    "        'diversity_ratio': diversity_ratio,\n",
    "        'appropriateness_rate': appropriateness_rate,\n",
    "        'response_lengths': response_length\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
