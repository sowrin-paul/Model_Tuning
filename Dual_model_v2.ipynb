{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2965ca1b",
   "metadata": {},
   "source": [
    "This is a performance testing with the dataset of adolescent on two model. A dual model setup is done here.\n",
    "\n",
    "The first model ***BERT*** is going to train on the emotion and the intent of the user and the ***T5*** model is going to generate text based on the questions.\n",
    "\n",
    "The datasets used here -> **casual_lm_train.jsonl** and **masked_lm_train.jsonl**\n",
    "\n",
    "*casual_lm_train* is used for the **T5** training and the *masked_lm* train is for the **Electra**.\n",
    "\n",
    "*T5*'s performance is going to evaluate by its perplexity that is how certain it's response is or other word what is it's accuracy to predict the next word.\n",
    "\n",
    "*BERT*'s performance is evaluated by it's accuracy to the prediction of the emotion and intention of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6da7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import evaluate\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "\n",
    "rogue_metric = evaluate.load('rogue')\n",
    "bleu_metric = evaluate.load('bleu')\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c4272",
   "metadata": {},
   "source": [
    "**Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec76593",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    jsonl_path = \"/home/ghost-ed/Documents/Model_Tuning/adolescent_chatbot_train.jsonl\"\n",
    "    work_dir = \"/home/ghost-ed/Documents/Model_Tuning\"\n",
    "\n",
    "    # label space\n",
    "    intents = (\n",
    "        \"seek_help\", \"venting\", \"ask_question\", \"share_success\", \"neutral\"\n",
    "    )\n",
    "    emotions = (\n",
    "        \"anxious\", \"sad\", \"angry\", \"lonely\", \"neutral\"\n",
    "    )\n",
    "\n",
    "    clf_model_name = \"bert-base-uncased\"\n",
    "    gen_model_name = \"t5-small\"\n",
    "\n",
    "    clf_epochs = 4\n",
    "    gen_epochs = 4\n",
    "    batch_size = 8\n",
    "    lr = 5e-5\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    # generation config\n",
    "    max_new_token = 96\n",
    "    do_sample = True\n",
    "    temperature = 0.9\n",
    "    top_p = 0.92\n",
    "    repetition_penalty = 1.08\n",
    "\n",
    "\n",
    "CFG = Config()\n",
    "os.makedirs(CFG.work_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f228277",
   "metadata": {},
   "source": [
    "**Dataset loading and heuristic labeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7a917",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'env (Python 3.13.7)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/ghost-ed/Documents/Model_Tuning/env/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def load_jsonl_messages(path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            msgs = obj.get('messages', [])\n",
    "            user = None\n",
    "            assistant = None\n",
    "            for m in msgs:\n",
    "                if m.get('role') == 'user' and user is not None:\n",
    "                    user = m.get('content', '').strip()\n",
    "                if m.get('role') == 'assistant' and assistant is not None:\n",
    "                    assistant = m.get('content', '').strip()\n",
    "            if user and assistant:\n",
    "                rows.append({\"text\": user, \"response\": assistant})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# intent/emontion heuristics\n",
    "INTENT_PATTERNS = {\n",
    "    \"seek_help\": [r\"help\", r\"what should i\", r\"how do i\", r\"can you\", r\"advice\"],\n",
    "    \"venting\": [r\"no one\", r\"nobody\", r\"so tired\", r\"fed up\", r\"i hate\"],\n",
    "    \"ask_question\": [r\"\\?$\", r\"why \", r\"what \", r\"how \", r\"when \", r\"where \"],\n",
    "    \"share_success\": [r\"i did (it|well)\", r\"i feel proud\", r\"happy to say\"],\n",
    "}\n",
    "\n",
    "\n",
    "EMOTION_PATTERNS = {\n",
    "    \"anxious\": [r\"anxious|nervous|worried|on edge|overthink\"],\n",
    "    \"sad\": [r\"sad|down|depress|worthless|cry\"],\n",
    "    \"angry\": [r\"angry|mad|furious|annoy|irritat\"],\n",
    "    \"lonely\": [r\"alone|lonely|isolated|no one\"],\n",
    "}\n",
    "\n",
    "\n",
    "CRISIS_PATTERNS = {\n",
    "    'self_harm': [r\"kill myself\", r\"suicide\", r\"end my life\", r\"hurt myself\"],\n",
    "    'abuse': [r\"abused\", r\"violence at home\", r\"beaten\", r\"forced\"],\n",
    "    'harm_others': [r\"hurt someone\", r\"kill them\", r\"revenge\"],\n",
    "}\n",
    "\n",
    "\n",
    "def first_match(text, patterns, default=\"neutral\") -> str:\n",
    "    t = text.lower()\n",
    "    for label, pats in patterns.items():\n",
    "        for p in pats:\n",
    "            if re.search(p, t):\n",
    "                return label\n",
    "    return default\n",
    "\n",
    "# synonyms for diversity\n",
    "SYNONYMS = {\n",
    "    'exam': ['test', 'assessment', 'paper'],\n",
    "    'school': ['class', 'college', 'campus'],\n",
    "    'anxious': ['nervous', 'worried', 'on edge'],\n",
    "    'angry': ['upset', 'frustrated', 'mad'],\n",
    "    'sad': ['down', 'blue', 'low'],\n",
    "    'friend': ['peer', 'classmate', 'buddy'],\n",
    "    'parents': ['family', 'mom and dad', 'guardians'],\n",
    "}\n",
    "\n",
    "def simple_augment(text, p=0.25, max_replacement=2) -> str:\n",
    "    tokens = re.findall(r\"\\w+|\\W\", text)\n",
    "    replaced = 0\n",
    "    for i, toks in enumerate(tokens):\n",
    "        low = toks.lower()\n",
    "        if low in SYNONYMS and random.random() < p and repalced < max_replacement:\n",
    "            tokens[i] = random.choice(SYNONYMS[low])\n",
    "            replaced += 1\n",
    "    return ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f2acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
